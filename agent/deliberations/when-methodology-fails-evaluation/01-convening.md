# Convening: Evaluation of "When This Methodology Fails"

**Date**: 2026-02-21

**Selection strategy**: Standard roster from `agent/roster.md`.

**Rationale**: Evaluating a self-critical essay about the methodology's limitations is a full-roster problem. Maya is essential because the essay was partly her recommendation and she'll know whether it delivered on the credibility promise. Frankie tests whether the essay's honesty serves the methodology's mission or undermines it. Joe checks whether the failure modes match real-world patterns. Vic demands evidence: are these failure modes documented or speculative? Tammy traces second-order effects: does publishing this change the methodology's feedback loops in beneficial or harmful ways?

**Composition notes**:
- **Maya × Frankie**: The core tension. Maya wants the essay to be maximally honest, even at the cost of making the methodology look weak. Frankie wants honesty in service of the mission, not at its expense. They'll disagree on whether the essay goes far enough vs. too far.
- **Vic × Joe**: Vic will demand evidence for the failure modes — are they observed or hypothetical? Joe will check whether similar methodologies' limitations documents actually helped or hurt adoption historically.
- **Tammy × all**: Tammy will trace how the essay changes the system — does it create a feedback loop where practitioners read limitations first and never engage, or does it build trust that leads to deeper engagement?

**Outcome**: Committee convened. See 01-roster.md.
